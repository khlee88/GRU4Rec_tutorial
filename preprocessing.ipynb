{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import ciso8601\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "https://2015.recsyschallenge.com/challenge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set data path\n",
    "#PATH_TO_ORIGINAL_DATA = '/PATH/TO/raw/'\n",
    "#PATH_TO_PROCESSED_DATA = '/PATH/TO/processed/'\n",
    "PATH_TO_ORIGINAL_DATA = '/home/khlee/git/recommendation/GRU4Rec_TensorFlow/data/raw/'\n",
    "PATH_TO_PROCESSED_DATA = '/home/khlee/git/recommendation/GRU4Rec_TensorFlow/data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 4.06 s, total: 32.3 s\n",
      "Wall time: 32.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33003944, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load data\n",
    "%time raw_data = pd.read_csv(PATH_TO_ORIGINAL_DATA + 'yoochoose-clicks.dat', sep=',', \\\n",
    "                   header=None, usecols=[0,1,2], dtype={0:np.int32, 1:str, 2:np.int64})\n",
    "raw_data.columns = ['SessionId', 'TimeStr', 'ItemId']\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## parameters\n",
    "sampling=True\n",
    "sample_rate = 0.1\n",
    "single_process=True\n",
    "file_type = \"sample\" if sampling==True else \"full\"\n",
    "file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3301436, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sampling\n",
    "### raw data의 수가 많으므로 tutorial을 원활히 수행하기 위해,\n",
    "### sessionId 기준으로 샘플링을 수행한다.\n",
    "random.seed(1050)\n",
    "if sampling:\n",
    "    u_sessid = raw_data.SessionId.unique()\n",
    "    s_sessid = random.sample(u_sessid.tolist(), int(len(u_sessid)*sample_rate))\n",
    "    raw_data = raw_data[np.in1d(raw_data.SessionId, s_sessid)]\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## multi processing: transpose timestr to timestamp\n",
    "num_cores = 8\n",
    "\n",
    "def timestr_to_timestamp(df):\n",
    "    df['timestamp'] = df.TimeStr.apply(lambda x: ciso8601.parse_datetime(x).timestamp())\n",
    "    return df\n",
    "\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.47 s, sys: 644 ms, total: 4.11 s\n",
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "## transpose timestr to timestamp\n",
    "if single_process:\n",
    "    ## single processing\n",
    "    %time raw_data['timestamp'] = raw_data.TimeStr.apply(lambda x: ciso8601.parse_datetime(x).timestamp())\n",
    "    data = raw_data\n",
    "    del(data['TimeStr'])\n",
    "else:\n",
    "    ## multi processing\n",
    "    %time data = parallelize_dataframe(raw_data, timestr_to_timestamp)\n",
    "    del(data['TimeStr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 204 ms, total: 3.5 s\n",
      "Wall time: 3.5 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>214701242</td>\n",
       "      <td>1.396804e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>214826623</td>\n",
       "      <td>1.396804e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>21</td>\n",
       "      <td>214838503</td>\n",
       "      <td>1.396861e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>21</td>\n",
       "      <td>214838503</td>\n",
       "      <td>1.396861e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>21</td>\n",
       "      <td>214838503</td>\n",
       "      <td>1.396861e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SessionId     ItemId     timestamp\n",
       "15          6  214701242  1.396804e+09\n",
       "16          6  214826623  1.396804e+09\n",
       "55         21  214838503  1.396861e+09\n",
       "56         21  214838503  1.396861e+09\n",
       "57         21  214838503  1.396861e+09"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sorted by sessionid, timestamp\n",
    "%time data = data.sort_values(['SessionId','timestamp'])\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 924972\n",
      "min length 1\n",
      "max length 200\n"
     ]
    }
   ],
   "source": [
    "## data length by sessionid\n",
    "session_lengths = data.groupby('SessionId').size()\n",
    "print(\"length:\", len(session_lengths))\n",
    "print(\"min length\", min(session_lengths))\n",
    "print(\"max length\", max(session_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter by session length\n",
    "### session이 2이상인 데이터만 필터한다.\n",
    "data = data[np.in1d(data.SessionId, session_lengths[session_lengths>=2].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 34452\n",
      "min length 1\n",
      "max length 13262\n"
     ]
    }
   ],
   "source": [
    "## data length by itemid\n",
    "item_supports = data.groupby('ItemId').size()\n",
    "print(\"length:\", len(item_supports))\n",
    "print(\"min length\", min(item_supports))\n",
    "print(\"max length\", max(item_supports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter by item length\n",
    "### item이 5이상인 데이터만 필터한다.\n",
    "data = data[np.in1d(data.ItemId, item_supports[item_supports>=5].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter by session length\n",
    "### item에 의해 session length가 1인 id생길 수 있으므로 한번더 수행한다.\n",
    "session_lengths = data.groupby('SessionId').size()\n",
    "data = data[np.in1d(data.SessionId, session_lengths[session_lengths>=2].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## split train & test set\n",
    "### 마지막 시간으로 부터 24시간 전까지 테스트 데이터로 사용하고 그 이전을 학습 데이터로 인덱스 구성\n",
    "tmax = data.timestamp.max()\n",
    "session_max_times = data.groupby('SessionId').timestamp.max()\n",
    "session_train = session_max_times[session_max_times < tmax-86400].index\n",
    "session_test = session_max_times[session_max_times >= tmax-86400].index\n",
    "### 학습 & 테스트 데이터 구성, 테스트 데이터의 아이템은 학습데이터에 있는 아이템만을 선택\n",
    "train = data[np.in1d(data.SessionId, session_train)]\n",
    "test = data[np.in1d(data.SessionId, session_test)]\n",
    "test = test[np.in1d(test.ItemId, train.ItemId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter by session length\n",
    "### test data의 item 필터 후 session length가 1이 될 수 있으므로, 필터링을 한번 더 수행\n",
    "tslength = test.groupby('SessionId').size()\n",
    "test = test[np.in1d(test.SessionId, tslength[tslength>=2].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train set\n",
      "\tEvents: 3140310\n",
      "\tSessions: 791707\n",
      "\tItems: 21878\n",
      "/home/khlee/git/recommendation/GRU4Rec_TensorFlow/data/processed/rsc15_train_sample.txt\n",
      "Test set\n",
      "\tEvents: 7451\n",
      "\tSessions: 1618\n",
      "\tItems: 1675\n",
      "/home/khlee/git/recommendation/GRU4Rec_TensorFlow/data/processed/rsc15_test_sample.txt\n"
     ]
    }
   ],
   "source": [
    "## save processed data\n",
    "print('Full train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train), \n",
    "        train.SessionId.nunique(), train.ItemId.nunique()))\n",
    "train.to_csv(PATH_TO_PROCESSED_DATA + 'rsc15_train_{}.txt'.format(file_type), \n",
    "             sep='\\t', index=False)\n",
    "print(PATH_TO_PROCESSED_DATA + 'rsc15_train_{}.txt'.format(file_type))\n",
    "print('Test set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(test), \n",
    "        test.SessionId.nunique(), test.ItemId.nunique()))\n",
    "test.to_csv(PATH_TO_PROCESSED_DATA + 'rsc15_test_{}.txt'.format(file_type), \n",
    "            sep='\\t', index=False)\n",
    "print(PATH_TO_PROCESSED_DATA + 'rsc15_test_{}.txt'.format(file_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "\tEvents: 3134339\n",
      "\tSessions: 790449\n",
      "\tItems: 21878\n",
      "/home/khlee/git/recommendation/GRU4Rec_TensorFlow/data/processed/rsc15_train_sample_trn.txt\n",
      "Validation set\n",
      "\tEvents: 5971\n",
      "\tSessions: 1258\n",
      "\tItems: 1399\n",
      "/home/khlee/git/recommendation/GRU4Rec_TensorFlow/data/processed/rsc15_train_sample_valid.txt\n"
     ]
    }
   ],
   "source": [
    "## make validation set\n",
    "### 동일한 과정으로 train data에서 validation data를 분리한다.\n",
    "tmax = train.timestamp.max()\n",
    "session_max_times = train.groupby('SessionId').timestamp.max()\n",
    "session_train = session_max_times[session_max_times < tmax-86400].index\n",
    "session_valid = session_max_times[session_max_times >= tmax-86400].index\n",
    "train_tr = train[np.in1d(train.SessionId, session_train)]\n",
    "valid = train[np.in1d(train.SessionId, session_valid)]\n",
    "valid = valid[np.in1d(valid.ItemId, train_tr.ItemId)]\n",
    "tslength = valid.groupby('SessionId').size()\n",
    "valid = valid[np.in1d(valid.SessionId, tslength[tslength>=2].index)]\n",
    "print('Train set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(train_tr), \n",
    "        train_tr.SessionId.nunique(), train_tr.ItemId.nunique()))\n",
    "train_tr.to_csv(PATH_TO_PROCESSED_DATA + 'rsc15_train_{}_trn.txt'.format(file_type), \n",
    "                sep='\\t', index=False)\n",
    "print(PATH_TO_PROCESSED_DATA + 'rsc15_train_{}_trn.txt'.format(file_type))\n",
    "print('Validation set\\n\\tEvents: {}\\n\\tSessions: {}\\n\\tItems: {}'.format(len(valid), \n",
    "        valid.SessionId.nunique(), valid.ItemId.nunique()))\n",
    "valid.to_csv(PATH_TO_PROCESSED_DATA + 'rsc15_train_{}_valid.txt'.format(file_type), \n",
    "             sep='\\t', index=False)\n",
    "print(PATH_TO_PROCESSED_DATA + 'rsc15_train_{}_valid.txt'.format(file_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
